{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "INSERT REPORT TITLE AND INFO HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import importlib\n",
    "# mypytable\n",
    "import mysklearn.mypytable\n",
    "importlib.reload(mysklearn.mypytable)\n",
    "from mysklearn.mypytable import MyPyTable\n",
    "# myevaluation\n",
    "import mysklearn.myevaluation\n",
    "importlib.reload(mysklearn.myevaluation)\n",
    "import mysklearn.myevaluation as me\n",
    "# myutils\n",
    "import mysklearn.myutils\n",
    "importlib.reload(mysklearn.myutils)\n",
    "import mysklearn.myutils as mu\n",
    "\n",
    "from mysklearn.myutils import combine_multiple_files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Data Cleaning\n",
    "\n",
    "### Preprocessing\n",
    "\n",
    "The data came as a large number of JSON files grouped into folders. Many of the files and folders were empty, so we began by deleting those. Some of the files contained irrelevant data/non-changing data, such as date of birth and device specs, so we also deleted those. What we were left with was three sets of JSON files, aggregator, fitness, and wellness.\n",
    "\n",
    "* Aggregator: This contains the most info. It has a list of metrics related to stress, calories, heart rate, and minor metrics related to activity\n",
    "* Fitness: This contains a list of activities and information about them. All of these activities are runs. Has attributes like distance, speed, heart rate, duration\n",
    "* Wellness: This mainly contained sleep data\n",
    "\n",
    "### Cleaning/Joining TODO\n",
    "\n",
    "Many instances in the dataset are missing values, or are just instances with basically no data. TODO: Make copies of the data without these bad instances\n",
    "\n",
    "Additionally, for this step we combine all of the many JSON files into one. First by joining all files within each folder, simply appending them onto each other. Then join the lists from each folder. \n",
    "\n",
    "We also opened the CSV's in Excel to guide our decision-making process for this step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning/Joining...\n",
    "# SLEEP\n",
    "# 1. load all files\n",
    "\n",
    "sleep_file_names = [\n",
    "    \"2021-04-23_2021-08-01_96200873_sleepData.csv\",\n",
    "    \"2021-08-01_2021-11-09_96200873_sleepData.csv\",\n",
    "    \"2021-11-09_2022-02-17_96200873_sleepData.csv\",\n",
    "    \"2022-02-17_2022-05-28_96200873_sleepData.csv\",\n",
    "    \"2022-05-28_2022-09-05_96200873_sleepData.csv\",\n",
    "    \"2022-09-05_2022-12-14_96200873_sleepData.csv\",\n",
    "    \"2022-12-14_2023-03-24_96200873_sleepData.csv\",\n",
    "    \"2023-03-24_2023-07-02_96200873_sleepData.csv\",\n",
    "    \"2023-07-02_2023-10-10_96200873_sleepData.csv\",\n",
    "    \"2023-10-10_2024-01-18_96200873_sleepData.csv\",\n",
    "    \"2024-01-18_2024-04-27_96200873_sleepData.csv\",\n",
    "    \"2024-04-27_2024-08-05_96200873_sleepData.csv\",\n",
    "    \"2024-08-05_2024-11-13_96200873_sleepData.csv\"   \n",
    "]\n",
    "\n",
    "full_sleep_table = combine_multiple_files(sleep_file_names, \"csv_converted_data/connect_wellness\")\n",
    "\n",
    "#current_table.pretty_print()\n",
    "# 3. Basic cleaning\n",
    "full_sleep_table.remove_rows_with_missing_values()\n",
    "full_sleep_table.remove_rows_where_col_equal_specified(\n",
    "    full_sleep_table.column_names.index(\"sleepWindowConfirmationType\"),\n",
    "    'OFF_WRIST'\n",
    ")\n",
    "\n",
    "# This is all of our joined sleep data\n",
    "#full_sleep_table.pretty_print()\n",
    "full_sleep_table.save_to_file('joined_nullfree_subsets/full_sleep.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Repeat for other file sets\n",
    "# ACTIVITY\n",
    "\n",
    "acitivity_files_names = [\n",
    "    \"jack-brandt@comcast.net_0_summarizedActivities.csv\",\n",
    "    \"jack-brandt@comcast.net_1001_summarizedActivities.csv\"\n",
    "]\n",
    "full_activity_table = combine_multiple_files(acitivity_files_names, \"csv_converted_data/connect_fitness\")\n",
    "full_activity_table.save_to_file('joined_nullfree_subsets/full_activity.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Repeat for other file sets\n",
    "# AGGREGATOR\n",
    "\n",
    "aggregator_file_names = [\n",
    "    \"UDSFile_2021-04-23_2021-08-01.csv\",\n",
    "    \"UDSFile_2021-08-01_2021-11-09.csv\",\n",
    "    \"UDSFile_2021-11-09_2022-02-17.csv\",\n",
    "    \"UDSFile_2022-02-17_2022-05-28.csv\",\n",
    "    \"UDSFile_2022-05-28_2022-09-05.csv\",\n",
    "    \"UDSFile_2022-09-05_2022-12-14.csv\",\n",
    "    \"UDSFile_2022-12-14_2023-03-24.csv\",\n",
    "    \"UDSFile_2023-03-24_2023-07-02.csv\",\n",
    "    \"UDSFile_2023-07-02_2023-10-10.csv\",\n",
    "    \"UDSFile_2023-10-10_2024-01-18.csv\",\n",
    "    \"UDSFile_2024-01-18_2024-04-27.csv\",\n",
    "    \"UDSFile_2024-04-27_2024-08-05.csv\",\n",
    "    \"UDSFile_2024-08-05_2024-11-13.csv\",\n",
    "]\n",
    "\n",
    "full_aggregator_table = combine_multiple_files(aggregator_file_names, \"csv_converted_data/connect_aggregator_data\")\n",
    "full_aggregator_table.save_to_file('joined_nullfree_subsets/full_aggregator.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Load the combined tables\n",
    "full_activity_table = MyPyTable().load_from_file(\n",
    "    \"joined_nullfree_subsets/full_activity.csv\"\n",
    ")\n",
    "full_sleep_table = MyPyTable().load_from_file(\"joined_nullfree_subsets/full_sleep.csv\")\n",
    "full_aggregator_table = MyPyTable().load_from_file(\"joined_nullfree_subsets/full_aggregator.csv\")\n",
    "\n",
    "# full_activity_table doesn't have a calendarDate column, so we need to add it\n",
    "# by converting the startTimeLocal column to a date\n",
    "start_time_index = full_activity_table.column_names.index(\"startTimeLocal\")\n",
    "\n",
    "# Add the column\n",
    "full_activity_table.column_names.append(\"calendarDate\")\n",
    "\n",
    "# Add the calendarDate to each row\n",
    "for data in full_activity_table.data:\n",
    "    timestamp = data[start_time_index] / 1000\n",
    "    dt_object = datetime.fromtimestamp(timestamp)\n",
    "    date = dt_object.strftime(\"%Y-%m-%d\")\n",
    "    data.append(date)\n",
    "\n",
    "# Now we can join the tables\n",
    "fully_joined_table = (full_activity_table.perform_inner_join(\n",
    "    full_sleep_table, [\"calendarDate\"]\n",
    ")).perform_inner_join(\n",
    "    full_aggregator_table, [\"calendarDate\"]\n",
    ")\n",
    "\n",
    "stress_dict = {}\n",
    "calendar_date_index = full_aggregator_table.column_names.index(\"calendarDate\")\n",
    "stress_index = full_aggregator_table.column_names.index(\"allDayStress/aggregatorList/0/maxStressLevel\")\n",
    "\n",
    "\n",
    "for row in full_aggregator_table.data:\n",
    "    stress_dict[row[calendar_date_index]] = row[stress_index]\n",
    "\n",
    "# Add the stress level to the fully joined table\n",
    "fully_joined_table.column_names.append(\"prevDayMaxStressLevel\")\n",
    "fully_joined_table_calender_date_index = fully_joined_table.column_names.index(\"calendarDate\")\n",
    "\n",
    "for row in fully_joined_table.data:\n",
    "    calendar_date = row[fully_joined_table_calender_date_index]\n",
    "\n",
    "    # Get the previous calendar date\n",
    "    prev_calendar_date = (datetime.strptime(calendar_date, \"%Y-%m-%d\") - timedelta(days=1)).strftime(\"%Y-%m-%d\")\n",
    "\n",
    "    # Get the stress level for the previous day\n",
    "    if prev_calendar_date in stress_dict:\n",
    "        row.append(stress_dict[prev_calendar_date])\n",
    "    else:\n",
    "        row.append(None)\n",
    "\n",
    "fully_joined_table.save_to_file(\"processed_data/fully_joined.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attribute                      min           max            mid            avg         median\n",
      "---------------------  -----------  ------------  -------------  -------------  -------------\n",
      "prevDayMaxStressLevel      73        99            86             91.8277        92\n",
      "avgHr                     132       176           154            153.445        153\n",
      "duration               702244         1.3104e+07    6.90314e+06    2.39065e+06    2.34151e+06\n",
      "avgSpeed                    0.1722    0.4365        0.30435        0.328907       0.3282\n"
     ]
    }
   ],
   "source": [
    "columns = [\"prevDayMaxStressLevel\", \"avgHr\", \"duration\", \"avgSpeed\"]\n",
    "class_column = \"avgSpeed\"\n",
    "column_index = {}\n",
    "\n",
    "def speed_discretizer(speed):\n",
    "    if speed < 0.32:\n",
    "        return \"slow\"\n",
    "    elif speed < 0.33:\n",
    "        return \"mild\"\n",
    "    else:\n",
    "        return \"fast\"\n",
    "    \n",
    "def heart_rate_discretizer(bpm):\n",
    "    if(bpm < 150):\n",
    "        return \"low\"\n",
    "    elif(bpm < 165):\n",
    "        return \"mid\"\n",
    "    \n",
    "    return \"high\"\n",
    "\n",
    "def stress_discretizer(stress):\n",
    "    if(stress < 90):\n",
    "        return \"low\"\n",
    "    elif(stress < 95):\n",
    "        return \"mid\"\n",
    "    \n",
    "    return \"high\"\n",
    "\n",
    "def duration_discretizer(duration):\n",
    "    if(duration < 2_000_000):\n",
    "        return \"low\"\n",
    "    elif(duration < 4_000_000):\n",
    "        return \"mid\"\n",
    "\n",
    "    return \"high\"\n",
    "\n",
    "for column in columns:\n",
    "    column_index[column] = fully_joined_table.column_names.index(column)\n",
    "\n",
    "data = []\n",
    "\n",
    "for row in fully_joined_table.data:\n",
    "    data.append([row[column_index[column]] for column in columns])\n",
    "\n",
    "table = MyPyTable(column_names=columns, data=data)\n",
    "\n",
    "# Remove rows with missing values\n",
    "table.remove_rows_with_missing_values()\n",
    "\n",
    "# Remove runs that are less than 10 minutes\n",
    "table.remove_row_if(table.get_index(\"duration\"), lambda x: x < 600000)\n",
    "table.remove_rows_where_col_equal_specified(table.get_index(class_column), 0)\n",
    "\n",
    "columns_to_extract = columns.copy()\n",
    "columns_to_extract.remove(class_column)\n",
    "\n",
    "table.save_to_file(\"processed_data/processed_data.csv\")\n",
    "\n",
    "X = [[stress_discretizer(row[0]), heart_rate_discretizer(row[1]), duration_discretizer(row[2])] for row in table.get_data_subset(columns_to_extract, False)]\n",
    "X_undiscretized = table.get_data_subset(columns_to_extract, False)\n",
    "y = [speed_discretizer(row) for row in table.get_column(class_column)]\n",
    "\n",
    "\n",
    "table.compute_summary_statistics(table.column_names).pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===========================================\n",
      "Dummy Summary Results\n",
      "===========================================\n",
      "1.\n",
      "    Accuracy: 0.43557422969187676\n",
      "    Error Rate: 0.5644257703081232\n",
      "2.\n",
      "    Precision: 0.43557422969187676\n",
      "    Recall: 1.0\n",
      "    F1 measure: 0.6068292682926829\n",
      "3. Confusion Matrix:\n",
      "Running      slow    mild    fast    Total    Recognition (%)\n",
      "---------  ------  ------  ------  -------  -----------------\n",
      "slow            0       0     175      175                  0\n",
      "mild            0       0     228      228                  0\n",
      "fast            0       0     311      311                100\n",
      "(Bonus) Classification Report:\n",
      "              precision    recall    f1-score    support\n",
      "------------  -----------  --------  ----------  ---------\n",
      "slow          0.0          0.0       0           175\n",
      "mild          0.0          0.0       0           228\n",
      "fast          0.44         1.0       0.61        311\n",
      "\n",
      "micro avg     0.44         1.0       0.61        714\n",
      "macro avg     0.15         0.33      0.2         714\n",
      "weighted avg  0.19         0.44      0.26        714\n"
     ]
    }
   ],
   "source": [
    "#Set up models # Add more from myclassifiers if time\n",
    "from mysklearn.myclassifiers import MyDecisionTreeClassifier, MyDummyClassifier, MyKNeighborsClassifier, MyNaiveBayesClassifier, MyRandomForestClassifier\n",
    "\n",
    "\n",
    "dummy_model = MyDummyClassifier() # Import these from myclassifiers\n",
    "knn_model = MyKNeighborsClassifier()\n",
    "bayes_model = MyNaiveBayesClassifier()\n",
    "tree_model = MyDecisionTreeClassifier()\n",
    "forest_model = MyRandomForestClassifier()\n",
    "\n",
    "labels = ['slow','mild','fast']\n",
    "pos_label='fast'\n",
    "\n",
    "# Repeat these following two lines for each possible model\n",
    "metrics, confusion, clas_repor = me.get_metrics_and_conf_matrix_and_report(dummy_model,10,X,y,labels,pos_label,'Running')\n",
    "mu.report_metrics_and_confusion('Dummy',metrics, confusion,\n",
    "    clas_repor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===========================================\n",
      "KNN Summary Results\n",
      "===========================================\n",
      "1.\n",
      "    Accuracy: 0.6932773109243697\n",
      "    Error Rate: 0.3067226890756303\n",
      "2.\n",
      "    Precision: 0.7507788161993769\n",
      "    Recall: 0.77491961414791\n",
      "    F1 measure: 0.7626582278481013\n",
      "3. Confusion Matrix:\n",
      "Running      slow    mild    fast    Total    Recognition (%)\n",
      "---------  ------  ------  ------  -------  -----------------\n",
      "slow          107      33      35      175            61.1429\n",
      "mild           36     147      45      228            64.4737\n",
      "fast           28      42     241      311            77.492\n",
      "(Bonus) Classification Report:\n",
      "              precision    recall    f1-score    support\n",
      "------------  -----------  --------  ----------  ---------\n",
      "slow          0.63         0.61      0.62        175\n",
      "mild          0.66         0.64      0.65        228\n",
      "fast          0.75         0.77      0.76        311\n",
      "\n",
      "accuracy                             0.69        714\n",
      "macro avg     0.68         0.68      0.68        714\n",
      "weighted avg  0.69         0.69      0.69        714\n"
     ]
    }
   ],
   "source": [
    "metrics, confusion, clas_repor = me.get_metrics_and_conf_matrix_and_report(knn_model,10,X_undiscretized,y,labels,pos_label,'Running')\n",
    "mu.report_metrics_and_confusion('KNN',metrics, confusion,\n",
    "    clas_repor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===========================================\n",
      "Bayes Summary Results\n",
      "===========================================\n",
      "1.\n",
      "    Accuracy: 0.453781512605042\n",
      "    Error Rate: 0.546218487394958\n",
      "2.\n",
      "    Precision: 0.5208791208791209\n",
      "    Recall: 0.7620578778135049\n",
      "    F1 measure: 0.618798955613577\n",
      "3. Confusion Matrix:\n",
      "Running      slow    mild    fast    Total    Recognition (%)\n",
      "---------  ------  ------  ------  -------  -----------------\n",
      "slow           72      29      74      175           41.1429\n",
      "mild           69      15     144      228            6.57895\n",
      "fast           62      12     237      311           76.2058\n",
      "(Bonus) Classification Report:\n",
      "              precision    recall    f1-score    support\n",
      "------------  -----------  --------  ----------  ---------\n",
      "slow          0.35         0.41      0.38        175\n",
      "mild          0.27         0.07      0.11        228\n",
      "fast          0.52         0.76      0.62        311\n",
      "\n",
      "accuracy                             0.45        714\n",
      "macro avg     0.38         0.41      0.37        714\n",
      "weighted avg  0.4          0.45      0.4         714\n"
     ]
    }
   ],
   "source": [
    "metrics, confusion, clas_repor = me.get_metrics_and_conf_matrix_and_report(MyNaiveBayesClassifier(),10,X,y,labels,pos_label,'Running')\n",
    "mu.report_metrics_and_confusion('Bayes',metrics, confusion,\n",
    "    clas_repor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "MyRandomForestClassifier.fit() missing 3 required positional arguments: 'N', 'M', and 'F'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[280], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m metrics, confusion, clas_repor \u001b[38;5;241m=\u001b[39m me\u001b[38;5;241m.\u001b[39mget_metrics_and_conf_matrix_and_report(forest_model,\u001b[38;5;241m10\u001b[39m,X,y,labels,pos_label,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRunning\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      2\u001b[0m mu\u001b[38;5;241m.\u001b[39mreport_metrics_and_confusion(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mForest\u001b[39m\u001b[38;5;124m'\u001b[39m,metrics, confusion,\n\u001b[1;32m      3\u001b[0m     clas_repor)\n",
      "File \u001b[0;32m/home/CPSC322/DataAlg-Final-Project-Running/mysklearn/myevaluation.py:641\u001b[0m, in \u001b[0;36mget_metrics_and_conf_matrix_and_report\u001b[0;34m(model, k, X, y, labels, pos_label, data_label)\u001b[0m\n\u001b[1;32m    623\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m'''Uses stratified k-fold cross validation to calculate classifier\u001b[39;00m\n\u001b[1;32m    624\u001b[0m \u001b[38;5;124;03mperformance metrics and confusion matrix\u001b[39;00m\n\u001b[1;32m    625\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    637\u001b[0m \u001b[38;5;124;03m    list: [accuracy, precision, recall, f1]\u001b[39;00m\n\u001b[1;32m    638\u001b[0m \u001b[38;5;124;03m    MyPyTable: The confusion matrix'''\u001b[39;00m\n\u001b[1;32m    640\u001b[0m folds \u001b[38;5;241m=\u001b[39m stratified_kfold_split(X,y,k)\n\u001b[0;32m--> 641\u001b[0m all_trues, all_preds \u001b[38;5;241m=\u001b[39m get_trues_and_preds_from_folds(model,folds,X,y)\n\u001b[1;32m    642\u001b[0m metrics\u001b[38;5;241m=\u001b[39m[mu\u001b[38;5;241m.\u001b[39mclassifier_accuracy(all_preds,all_trues),\u001b[38;5;66;03m#This function bc we just want\u001b[39;00m\n\u001b[1;32m    643\u001b[0m          \u001b[38;5;66;03m# only the accuracy,\u001b[39;00m\n\u001b[1;32m    644\u001b[0m          binary_precision_score(all_trues,all_preds,pos_label\u001b[38;5;241m=\u001b[39mpos_label),\n\u001b[1;32m    645\u001b[0m          binary_recall_score(all_trues,all_preds,pos_label\u001b[38;5;241m=\u001b[39mpos_label),\n\u001b[1;32m    646\u001b[0m          binary_f1_score(all_trues,all_preds,pos_label\u001b[38;5;241m=\u001b[39mpos_label)]\n\u001b[1;32m    647\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m metrics, cross_confusion_matrix_method(model,k,X,y,labels,data_label,\n\u001b[1;32m    648\u001b[0m         \u001b[38;5;28;01mTrue\u001b[39;00m), classification_report(all_trues,all_preds)\n",
      "File \u001b[0;32m/home/CPSC322/DataAlg-Final-Project-Running/mysklearn/myevaluation.py:611\u001b[0m, in \u001b[0;36mget_trues_and_preds_from_folds\u001b[0;34m(model, folds, X, y)\u001b[0m\n\u001b[1;32m    609\u001b[0m X_train \u001b[38;5;241m=\u001b[39m [X[i] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m fold[\u001b[38;5;241m0\u001b[39m]]\n\u001b[1;32m    610\u001b[0m y_train \u001b[38;5;241m=\u001b[39m [y[i] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m fold[\u001b[38;5;241m0\u001b[39m]]\n\u001b[0;32m--> 611\u001b[0m model\u001b[38;5;241m.\u001b[39mfit(X_train,y_train)\n\u001b[1;32m    612\u001b[0m \u001b[38;5;66;03m# Make predictions\u001b[39;00m\n\u001b[1;32m    613\u001b[0m X_test \u001b[38;5;241m=\u001b[39m [X[i] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m fold[\u001b[38;5;241m1\u001b[39m]]\n",
      "\u001b[0;31mTypeError\u001b[0m: MyRandomForestClassifier.fit() missing 3 required positional arguments: 'N', 'M', and 'F'"
     ]
    }
   ],
   "source": [
    "metrics, confusion, clas_repor = me.get_metrics_and_conf_matrix_and_report(tree_model,10,X,y,labels,pos_label,'Running')\n",
    "mu.report_metrics_and_confusion('Forest',metrics, confusion,\n",
    "    clas_repor)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
